{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Statistical Modeling\n",
    "\n",
    "## Objective\n",
    "Build predictive models to estimate TotalClaims (insurance risk) using policy and vehicle features.\n",
    "\n",
    "## Models\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "\n",
    "## Evaluation\n",
    "Using RMSE, MAE, and R² metrics, plus SHAP for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.loader import load_data\n",
    "from src.modeling import DataPreprocessor, train_linear_regression, train_random_forest, train_xgboost, evaluate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Using the first 100,000 rows to manage memory efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data efficiently\n",
    "filepath = '../data/raw/MachineLearningRating_v3.txt'\n",
    "\n",
    "# Use nrows to limit dataset size and avoid memory issues\n",
    "print(\"Loading data (first 100,000 rows)...\")\n",
    "df = pd.read_csv(filepath, sep='|', low_memory=False, nrows=100000)\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features and Target\n",
    "target_col = 'TotalClaims'\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=[target_col])\n",
    "print(f\"After dropping missing target: {len(df):,} rows\")\n",
    "\n",
    "# Feature Selection\n",
    "categorical_features = ['Gender', 'Province', 'VehicleType', 'make', 'bodytype']\n",
    "numerical_features = ['RegistrationYear', 'Cylinders', 'cubiccapacity', 'kilowatts', 'NumberOfDoors', 'CapitalOutstanding']\n",
    "\n",
    "# Check if features exist\n",
    "all_features = categorical_features + numerical_features\n",
    "missing_features = [f for f in all_features if f not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"Warning: Missing features: {missing_features}\")\n",
    "    # Remove missing features\n",
    "    categorical_features = [f for f in categorical_features if f in df.columns]\n",
    "    numerical_features = [f for f in numerical_features if f in df.columns]\n",
    "\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"Numerical features ({len(numerical_features)}): {numerical_features}\")\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[categorical_features + numerical_features].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor(categorical_features, numerical_features)\n",
    "\n",
    "# Fit and transform\n",
    "print(\"Fitting preprocessor...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"\\nProcessed training shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test shape: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "### 5.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Linear Regression...\")\n",
    "lr_model = train_linear_regression(X_train_processed, y_train)\n",
    "lr_eval = evaluate_model(lr_model, X_test_processed, y_test)\n",
    "\n",
    "print(\"\\n=== Linear Regression Results ===\")\n",
    "for metric, value in lr_eval.items():\n",
    "    print(f\"{metric}: {value:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest...\")\n",
    "rf_model = train_random_forest(X_train_processed, y_train, n_estimators=50, random_state=42)\n",
    "rf_eval = evaluate_model(rf_model, X_test_processed, y_test)\n",
    "\n",
    "print(\"\\n=== Random Forest Results ===\")\n",
    "for metric, value in rf_eval.items():\n",
    "    print(f\"{metric}: {value:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training XGBoost...\")\n",
    "xgb_model = train_xgboost(X_train_processed, y_train, random_state=42)\n",
    "xgb_eval = evaluate_model(xgb_model, X_test_processed, y_test)\n",
    "\n",
    "print(\"\\n=== XGBoost Results ===\")\n",
    "for metric, value in xgb_eval.items():\n",
    "    print(f\"{metric}: {value:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Linear Regression': lr_eval,\n",
    "    'Random Forest': rf_eval,\n",
    "    'XGBoost': xgb_eval\n",
    "}).T\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string())\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, metric in enumerate(['RMSE', 'MAE', 'R2']):\n",
    "    comparison_df[metric].plot(kind='bar', ax=axes[idx], color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "    axes[idx].set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel(metric)\n",
    "    axes[idx].set_xlabel('Model')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel comparison plot saved to reports/model_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Interpretability (SHAP)\n",
    "\n",
    "Using SHAP to understand feature importance and model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "print(\"Generating SHAP values for XGBoost model...\")\n",
    "\n",
    "# Use TreeExplainer for tree-based models (faster)\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "\n",
    "# Calculate SHAP values for test set (use subset for speed)\n",
    "X_test_sample = X_test_processed[:1000]  # Use first 1000 samples\n",
    "shap_values = explainer(X_test_sample)\n",
    "\n",
    "print(f\"SHAP values computed for {len(X_test_sample)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_test_sample, show=False)\n",
    "plt.title('SHAP Summary Plot - Feature Importance', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/shap_summary_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSHAP summary plot saved to reports/shap_summary_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for mean absolute SHAP values\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.plots.bar(shap_values, show=False)\n",
    "plt.title('SHAP Feature Importance (Mean |SHAP value|)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/shap_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"SHAP feature importance plot saved to reports/shap_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Business Insights and Recommendations\n",
    "\n",
    "### Model Performance Analysis\n",
    "\n",
    "Based on the evaluation metrics:\n",
    "\n",
    "1. **Best Performing Model**: The model with the lowest RMSE and MAE, and highest R² should be deployed.\n",
    "   - Tree-based models (Random Forest, XGBoost) typically outperform Linear Regression for insurance data due to non-linear relationships.\n",
    "\n",
    "2. **Feature Importance**: SHAP analysis reveals which features most influence claim predictions:\n",
    "   - High-impact features should be prioritized in underwriting decisions\n",
    "   - Low-impact features may be candidates for removal in future iterations\n",
    "\n",
    "### Recommendations for Low-Risk Client Identification\n",
    "\n",
    "1. **Risk Scoring**: Use the model to generate risk scores for each policy\n",
    "2. **Threshold Definition**: Set a claims prediction threshold to identify \"low-risk\" clients\n",
    "3. **Premium Optimization**: Offer competitive premiums to clients predicted as low-risk\n",
    "4. **Continuous Monitoring**: Regularly retrain models with new claim data to maintain accuracy\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Model Deployment**: Integrate the best model into the pricing pipeline\n",
    "2. **A/B Testing**: Test premium adjustments on a subset of low-risk clients\n",
    "3. **Feature Engineering**: Explore additional derived features (e.g., vehicle age, claims history ratios)\n",
    "4. **Hyperparameter Tuning**: Optimize model parameters for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ Successfully trained three models: Linear Regression, Random Forest, and XGBoost  \n",
    "✅ Evaluated models using RMSE, MAE, and R² metrics  \n",
    "✅ Generated SHAP visualizations for model interpretability  \n",
    "✅ Provided business recommendations based on model insights  \n",
    "\n",
    "**Task 4 Complete!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
